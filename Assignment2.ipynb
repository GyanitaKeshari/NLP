{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'constitution', 'declares', 'India', 'a', 'sovereign', ',', 'socialist', ',', 'secular', ',', 'democratic', 'republic', ',', 'assuring', 'its', 'citizens', 'justice', ',', 'equality', 'and', 'liberty', ',', 'and', 'endeavours', 'to', 'promote', 'fraternity', '.', 'The', 'original', '1950', 'constitution', 'is', 'preserved', 'in', 'a', 'helium', '-', 'filled', 'case', 'at', 'the', 'Parliament', 'House', 'in', 'New', 'Delhi', '.']\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "#WordPunctTokenizer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "sentence_data = \"The constitution declares India a sovereign, socialist, secular, democratic republic, assuring its citizens justice, equality and liberty, and endeavours to promote fraternity. The original 1950 constitution is preserved in a helium-filled case at the Parliament House in New Delhi.\"\n",
    "\n",
    "tokens=WordPunctTokenizer()\n",
    "output=tokens.tokenize(sentence_data)\n",
    "print(output)\n",
    "print(len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'constitution', 'declares', 'India', 'a', 'sovereign,', 'socialist,', 'secular,', 'democratic', 'republic,', 'assuring', 'its', 'citizens', 'justice,', 'equality', 'and', 'liberty,', 'and', 'endeavours', 'to', 'promote', 'fraternity.', 'The', 'original', '1950', 'constitution', 'is', 'preserved', 'in', 'a', 'helium-filled', 'case', 'at', 'the', 'Parliament', 'House', 'in', 'New', 'Delhi.']\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "# Whitespace Tokenizer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "sentence_data = \"The constitution declares India a sovereign, socialist, secular, democratic republic, assuring its citizens justice, equality and liberty, and endeavours to promote fraternity. The original 1950 constitution is preserved in a helium-filled case at the Parliament House in New Delhi.\"\n",
    "\n",
    "tokens=WhitespaceTokenizer()\n",
    "output=tokens.tokenize(sentence_data)\n",
    "print(output)\n",
    "print(len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'constitution', 'declares', 'India', 'a', 'sovereign', ',', 'socialist', ',', 'secular', ',', 'democratic', 'republic', ',', 'assuring', 'its', 'citizens', 'justice', ',', 'equality', 'and', 'liberty', ',', 'and', 'endeavours', 'to', 'promote', 'fraternity.', 'The', 'original', '1950', 'constitution', 'is', 'preserved', 'in', 'a', 'helium-filled', 'case', 'at', 'the', 'Parliament', 'House', 'in', 'New', 'Delhi', '.']\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "#TreebankWordTokenizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "sentence_data = \"The constitution declares India a sovereign, socialist, secular, democratic republic, assuring its citizens justice, equality and liberty, and endeavours to promote fraternity. The original 1950 constitution is preserved in a helium-filled case at the Parliament House in New Delhi.\"\n",
    "\n",
    "tokens=TreebankWordTokenizer()\n",
    "output=tokens.tokenize(sentence_data)\n",
    "print(output)\n",
    "print(len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[u'A constitut aggreg fundament principl establish preced constitut legal basi politi , organis type entiti commonli determin entiti govern .']\n"
     ]
    }
   ],
   "source": [
    "# Stemming\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "paragraph =\"\"\"A constitution is an aggregate of fundamental principles or established precedents that constitute the legal basis of a polity, organisation or other type of entity and commonly determine how that entity is to be governed.\"\"\"\n",
    "\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "print(len(sentences))\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i] = ' '.join(words) \n",
    "\n",
    "print(sentences) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'A constitut aggreg fundament principl establish preced constitut legal basi politi , organis type entiti commonli determin entiti govern .']\n"
     ]
    }
   ],
   "source": [
    "# Lemmitizing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "paragraph =\"\"\"A constitution is an aggregate of fundamental principles or established precedents that constitute the legal basis of a polity, organisation or other type of entity and commonly determine how that entity is to be governed.\"\"\"\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i] = ' '.join(words) \n",
    "\n",
    "print(sentences) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'This', u'is', u'a', u'cooool', u'#dummysmiley', u':', u':-)', u':-P', u'<3', u'and', u'some', u'arrows', u'<', u'>', u'->', u'<--']\n",
      "16\n",
      "['This', 'is', 'a', 'test', 'in', 'spite']\n",
      "['In', 'a_little', 'or', 'a_little_bit', 'or', 'a_lot', 'in_spite_of']\n",
      "['( a * ( b + c ))', 'ab', '( a-c )']\n",
      "[u'Testing', u'Python', u'.$$&* \\nis', u' Testing2']\n",
      "<ConditionalFreqDist with 2 conditions>\n"
     ]
    }
   ],
   "source": [
    "# DIFFERENT TYPES OF TOKENIZERS\n",
    "\n",
    "#1 Tweet Tokenizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "sentence_data = \"This is a cooool #dummysmiley: :-) :-P <3 and some arrows < > -> <--\"\n",
    "tokens=TweetTokenizer()\n",
    "output=tokens.tokenize(sentence_data)\n",
    "print(output)\n",
    "print(len(output))\n",
    "\n",
    "#2 Multi-Word Expression Tokenizer\n",
    "from nltk.tokenize import MWETokenizer\n",
    "tokenizer = MWETokenizer([('a', 'little'), ('a', 'little', 'bit'), ('a', 'lot')])\n",
    "tokenizer.add_mwe(('in', 'spite', 'of'))\n",
    "s1 = tokenizer.tokenize('This is a test in spite'.split())\n",
    "print(s1)\n",
    "s2 = tokenizer.tokenize('In a little or a little bit or a lot in spite of'.split())\n",
    "print(s2)\n",
    "\n",
    "#3 SExprTokenizer\n",
    "from nltk.tokenize import SExprTokenizer \n",
    "tk = SExprTokenizer() \n",
    "s3 = \"( a * ( b + c ))ab( a-c )\"\n",
    "s = tk.tokenize(s3) \n",
    "print(s) \n",
    "\n",
    "#4 TabTokenizer() method from nltk \n",
    "from nltk.tokenize import TabTokenizer \n",
    "tk = TabTokenizer() \n",
    "s5 = \"Testing\\tPython\\t.$$&* \\nis\\t Testing2\"\n",
    "s6 = tk.tokenize(s5) \n",
    "print(s6) \n",
    "\n",
    "# ConditionalFreqDist()\n",
    "from nltk.probability import ConditionalFreqDist \n",
    "from nltk.tokenize import word_tokenize \n",
    "tk = ConditionalFreqDist() \n",
    "s4 = \"Testing Python Testing\"\n",
    "     \n",
    "for word in word_tokenize(s4): \n",
    "   condition = len(word) \n",
    "   tk[condition][word] += 1\n",
    "     \n",
    "print(tk) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
